{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552e70a3",
   "metadata": {},
   "source": [
    "# Text Representations: One-Hot, Bag of Words, TF/IDF\n",
    "\n",
    "Learn simple, non-math ways to turn text into numbers with beginner notes and tiny examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43696bca",
   "metadata": {},
   "source": [
    "> Beginner quick start\n",
    ">\n",
    "> - Run cells from top to bottom. If you change earlier text, re-run later cells.\n",
    "> - Each section has a short note on what to run and how to read the outputs.\n",
    "> - Use the tiny 3-sentence corpus to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851562e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokenize(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf48a3",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "What it does:\n",
    "Turns each word in a sentence into a simple list of numbers, where only one number is \"on\" (1) and the rest are \"off\" (0). This shows which word it is, without implying any meaning or similarity.\n",
    "\n",
    "Why it's useful:\n",
    "It's a basic way to let computers \"see\" which words are present so we can start working with text.\n",
    "\n",
    "Example (tiny):\n",
    "Sentence: \"I like pizza\"\n",
    "Vocabulary: [\"i\", \"like\", \"pizza\"]\n",
    "One‑hot matrix (rows = tokens in order, columns = unique words):\n",
    "| Word | i | like | pizza |\n",
    "|------|---|------|-------|\n",
    "| i    | 1 | 0    | 0     |\n",
    "| like | 0 | 1    | 0     |\n",
    "| pizza| 0 | 0    | 1     |\n",
    "\n",
    "How rows and tokens work\n",
    "- Each row corresponds to a token (word) in the sentence, in order.\n",
    "- Number of rows = number of tokens; number of columns = number of unique words (vocabulary).\n",
    "\n",
    "Beginner notes: One‑Hot\n",
    "- Run the next cell.\n",
    "- Look for: tokens (cleaned words), vocabulary (unique words), and matrix shape (rows=tokens; columns=vocab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(sentence):\n",
    "    tokens = clean_tokenize(sentence)\n",
    "    vocabulary = sorted(set(tokens))\n",
    "    word_to_index = {w: i for i, w in enumerate(vocabulary)}\n",
    "    mat = np.zeros((len(tokens), len(vocabulary)), dtype=int)\n",
    "    for i, w in enumerate(tokens):\n",
    "        mat[i, word_to_index[w]] = 1\n",
    "    return mat, vocabulary, tokens\n",
    "\n",
    "\n",
    "sentence = 'Should we go to a pizzeria or do you prefer a restaurant?'\n",
    "one_hot_matrix, vocabulary, tokens = one_hot_encoding(sentence)\n",
    "print('Tokens:', tokens)\n",
    "print('Vocab ({}):'.format(len(vocabulary)), vocabulary)\n",
    "print('One-Hot shape:', one_hot_matrix.shape)\n",
    "one_hot_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9966c4",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW)\n",
    "\n",
    "What it does:\n",
    "Counts how many times each word appears in each sentence (or document). It builds a vocabulary of unique words and then makes a table of counts.\n",
    "\n",
    "Why it’s useful:\n",
    "Lets us compare sentences by the words they contain and how often. Helpful for search, clustering, or as input features.\n",
    "\n",
    "Tiny example (3 sentences)\n",
    "1) \"This movie is awesome awesome\"\n",
    "2) \"I do not say is good, but neither awesome\"\n",
    "3) \"Awesome? Only a fool can say that\"\n",
    "\n",
    "Vocabulary (sorted): [\"a\", \"awesome\", \"but\", \"can\", \"do\", \"fool\", \"good\", \"i\", \"is\", \"movie\", \"neither\", \"not\", \"only\", \"say\", \"that\", \"this\"]\n",
    "\n",
    "Counts matrix (rows = sentences, columns = vocabulary):\n",
    "| sentence | a | awesome | but | can | do | fool | good | i | is | movie | neither | not | only | say | that | this |\n",
    "|---------:|:-:|:------:|:---:|:---:|:--:|:----:|:----:|:-:|:--:|:-----:|:-------:|:---:|:----:|:---:|:----:|:----:|\n",
    "| 1        | 0 |   2    |  0  |  0  | 0  |  0   |  0   | 0 |  1 |   1   |    0    |  0  |  0   |  0  |  0   |  1   |\n",
    "| 2        | 0 |   1    |  1  |  0  | 1  |  0   |  1   | 1 |  1 |   0   |    1    |  1  |  0   |  1  |  0   |  0   |\n",
    "| 3        | 1 |   1    |  0  |  1  | 0  |  1   |  0   | 0 |  0 |   0   |    0    |  0  |  1   |  1  |  1   |  0   |\n",
    "\n",
    "How to read it\n",
    "- Row 1 has “awesome” twice, and includes “is”, “movie”, and “this” once each.\n",
    "- Row 2 includes single‑occurrence words like “but”, “do”, “good”, “i”, “is”, “neither”, “not”, “say”, and one “awesome”.\n",
    "- Row 3 contains words like “a”, “awesome”, “can”, “fool”, “only”, “say”, “that” each once.\n",
    "\n",
    "Notes\n",
    "- Bag of Words ignores order: “movie awesome” equals “awesome movie”.\n",
    "- It captures counts, not meaning. TF‑IDF and embeddings improve on this.\n",
    "\n",
    "Beginner notes: BoW\n",
    "- Run the next two cells.\n",
    "- The table shows rows=sentences and columns=words; values are counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(sentences):\n",
    "    tokenized = [clean_tokenize(s) for s in sentences]\n",
    "    vocab = sorted(set(w for sent in tokenized for w in sent))\n",
    "    w2i = {w: i for i, w in enumerate(vocab)}\n",
    "    mat = np.zeros((len(sentences), len(vocab)), dtype=int)\n",
    "    for i, sent in enumerate(tokenized):\n",
    "        for w in sent:\n",
    "            mat[i, w2i[w]] += 1\n",
    "    return vocab, mat\n",
    "\n",
    "\n",
    "corpus = [\n",
    "    'This movie is awesome awesome',\n",
    "    'I do not say is good, but neither awesome',\n",
    "    'Awesome? Only a fool can say that'\n",
    "]\n",
    "vocab_bow, bow_matrix = bag_of_words(corpus)\n",
    "print('Vocab size:', len(vocab_bow), '| Matrix:', bow_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9320adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df = pd.DataFrame(bow_matrix, columns=vocab_bow)\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027aad9",
   "metadata": {},
   "source": [
    "## Term Frequency (TF) and TF‑IDF\n",
    "\n",
    "What it does:\n",
    "- TF: Shows how often each word appears in a sentence, relative to the sentence length.\n",
    "- IDF: Downweights words that appear in many sentences; upweights words that are rare across sentences.\n",
    "- TF‑IDF = TF × IDF: Highlights words that are frequent in one sentence but uncommon overall.\n",
    "\n",
    "Why it’s useful:\n",
    "Helps find words that are distinctive to each sentence, useful for search, summarization, and feature engineering.\n",
    "\n",
    "How to read TF and TF‑IDF\n",
    "- TF: Within one sentence, count each word and divide by total words in that sentence (row sums ≈ 1.0).\n",
    "- IDF: Higher for rarer words; equals 1.0 for words present in every sentence (with smoothing).\n",
    "- TF‑IDF: Large when a word is frequent in a sentence and rare across others.\n",
    "\n",
    "Tiny example (same 3 sentences)\n",
    "1) \"this movie is awesome awesome\"\n",
    "2) \"i do not say is good, but neither awesome\"\n",
    "3) \"awesome? only a fool can say that\"\n",
    "\n",
    "Intuition\n",
    "- “awesome” appears in all sentences, so its IDF is lower than a word appearing in only one sentence.\n",
    "- A word that repeats in one sentence can still get a higher TF‑IDF for that sentence.\n",
    "\n",
    "Tiny numeric walk‑through for “awesome”\n",
    "- Sentence lengths: 5, 9, 7 → TF1=2/5=0.40, TF2=1/9≈0.11, TF3=1/7≈0.14\n",
    "- With sklearn‑style smoothing: idf = log((1+N)/(1+df)) + 1 → N=3, df(awesome)=3 → IDF=1.0\n",
    "- TF‑IDF values: 0.40, ~0.11, ~0.14 (highest in sentence 1 due to repetition)\n",
    "\n",
    "Beginner notes: TF/IDF\n",
    "- Run the next cells to compute and view tables.\n",
    "- Larger TF‑IDF means “important for that sentence and uncommon overall”.\n",
    "- Optional: print top TF‑IDF words per sentence to see the standouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34322f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(sentences):\n",
    "    tokenized = [clean_tokenize(s) for s in sentences]\n",
    "    vocab = sorted(set(w for sent in tokenized for w in sent))\n",
    "    w2i = {w: i for i, w in enumerate(vocab)}\n",
    "    tf = np.zeros((len(sentences), len(vocab)), dtype=np.float32)\n",
    "    for i, words in enumerate(tokenized):\n",
    "        n = max(1, len(words))\n",
    "        for w in words:\n",
    "            tf[i, w2i[w]] += 1.0 / n\n",
    "    return tf, vocab\n",
    "\n",
    "\n",
    "def compute_idf(sentences, vocab):\n",
    "    token_sets = [set(clean_tokenize(s)) for s in sentences]\n",
    "    N = len(sentences)\n",
    "    w2i = {w: i for i, w in enumerate(vocab)}\n",
    "    idf = np.zeros(len(vocab), dtype=np.float32)\n",
    "    for w in vocab:\n",
    "        df = sum(1 for s in token_sets if w in s)\n",
    "        idf[w2i[w]] = np.log((1 + N) / (1 + df)) + \\\n",
    "            1.0  # sklearn-style smoothing\n",
    "    return idf\n",
    "\n",
    "\n",
    "def tf_idf(sentences):\n",
    "    tf, vocab = compute_tf(sentences)\n",
    "    idf = compute_idf(sentences, vocab)\n",
    "    return vocab, tf * idf\n",
    "\n",
    "\n",
    "vocabulary, tf_idf_matrix = tf_idf(corpus)\n",
    "tf_matrix, tf_vocab = compute_tf(corpus)\n",
    "idf_vector = compute_idf(corpus, tf_vocab)\n",
    "print('TF-IDF shape:', tf_idf_matrix.shape)\n",
    "tf_df = pd.DataFrame(tf_matrix, columns=tf_vocab)\n",
    "idf_df = pd.DataFrame([idf_vector], columns=tf_vocab)\n",
    "tfidf_df = pd.DataFrame(tf_idf_matrix, columns=vocabulary)\n",
    "display(tf_df.round(2))\n",
    "display(idf_df.round(2))\n",
    "display(tfidf_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94992f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top TF-IDF terms per sentence\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def top_tfidf_per_doc(vocab, tfidf_matrix, top_k=3):\n",
    "    for i in range(tfidf_matrix.shape[0]):\n",
    "        row = tfidf_matrix[i]\n",
    "        idxs = np.argsort(-row)[:top_k]\n",
    "        pairs = [(vocab[j], float(row[j])) for j in idxs if row[j] > 0]\n",
    "        print(f'Sentence {i+1}: {pairs}')\n",
    "\n",
    "\n",
    "top_tfidf_per_doc(vocabulary, tf_idf_matrix, top_k=3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
